# Claude Code Rules - Hackathon II Full Stack Todo App

This file provides runtime development guidance for Claude Code working on the Hackathon II Todo Application project.

You are an expert AI assistant specializing in Spec-Driven Development (SDD). Your primary goal is to work with the architect to build high-quality products.

**Project**: Multi-user Full-Stack Todo Web Application with AI Chatbot and Local Kubernetes Deployment
**Phases**: Phase 2 of 5 (Full-Stack Web Application) + Phase 3 of 5 (AI Chatbot Integration) + Phase 4 of 5 (Local Kubernetes Deployment)
**Constitution**: See `.specify/memory/constitution.md` (authoritative source)
**Spec-Kit Config**: See `.spec-kit/config.yaml`

---

## Phase 2: Full-Stack Web Application


This is a **strict Spec-Driven Development** project for Hackathon II. All code is generated by Claude Code from approved specificationsâ€”**zero manual coding allowed**. This is Phase 2 of 5 (Full-Stack Web Application)

### Technology Stack
- **Frontend**: Next.js 15+ (App Router), TypeScript, Tailwind CSS, shadcn/ui, GSAP/Framer Motion
- **Backend**: UV Pacakage Manager, Python 3.13+, FastAPI, SQLModel, Better Auth (JWT)
- **Database**: Neon Serverless PostgreSQL
- **Deployment**: Vercel (frontend), Hugging Face Spaces (backend)

### Monorepo Structure
```
Phase02_FullStackWebApp/
â”œâ”€â”€ CLAUDE.md                   # This file (root-level guidance)
â”œâ”€â”€ .specify/
â”‚   â”œâ”€â”€ config.yaml            # Spec-Kit Plus configuration
â”‚   â””â”€â”€ memory/
â”‚       â””â”€â”€ constitution.md    # Project principles (READ FIRST)
â”œâ”€â”€ specs/                     # Feature specifications
â”‚   â”œâ”€â”€ overview.md
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ database/
â”œâ”€â”€ history/
â”‚   â”œâ”€â”€ prompts/               # PHRs (all interactions)
â”‚   â””â”€â”€ adr/                   # Architecture Decision Records
â”œâ”€â”€ frontend/                  # Next.js application
â”‚   â””â”€â”€ CLAUDE.md             # Frontend-specific rules
â””â”€â”€ backend/                   # FastAPI application
    â””â”€â”€ CLAUDE.md             # Backend-specific rules
```

### Workspace-Specific Guidelines
- **Root Level** (this file): Cross-cutting concerns, monorepo coordination, SDD workflow
- **Frontend**: See `frontend/CLAUDE.md` for Next.js 15+ App Router specific rules
- **Backend**: See `backend/CLAUDE.md` for FastAPI + SQLModel specific rules

### Project Overview

This is a **strict Spec-Driven Development** project for Hackathon II. All code is generated by Claude Code from approved specificationsâ€”**zero manual coding allowed**.

#### Technology Stack
- **Frontend**: Next.js 15+ (App Router), TypeScript, Tailwind CSS, shadcn/ui, GSAP/Framer Motion
- **Backend**: UV Pacakage Manager, Python 3.13+, FastAPI, SQLModel, Better Auth (JWT)
- **Database**: Neon Serverless PostgreSQL
- **Deployment**: Vercel (frontend), Hugging Face Spaces (backend)

#### Monorepo Structure
```
Phase02_FullStackWebApp/
â”œâ”€â”€ CLAUDE.md                   # This file (root-level guidance)
â”œâ”€â”€ .specify/
â”‚   â”œâ”€â”€ config.yaml            # Spec-Kit Plus configuration
â”‚   â””â”€â”€ memory/
â”‚       â””â”€â”€ constitution.md    # Project principles (READ FIRST)
â”œâ”€â”€ specs/                     # Feature specifications
â”‚   â”œâ”€â”€ overview.md
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ database/
â”œâ”€â”€ history/
â”‚   â”œâ”€â”€ prompts/               # PHRs (all interactions)
â”‚   â””â”€â”€ adr/                   # Architecture Decision Records
â”œâ”€â”€ frontend/                  # Next.js application
â”‚   â””â”€â”€ CLAUDE.md             # Frontend-specific rules
â””â”€â”€ backend/                   # FastAPI application
    â””â”€â”€ CLAUDE.md             # Backend-specific rules
```

#### Workspace-Specific Guidelines
- **Root Level** (this file): Cross-cutting concerns, monorepo coordination, SDD workflow
- **Frontend**: See `frontend/CLAUDE.md` for Next.js 15+ App Router specific rules
- **Backend**: See `backend/CLAUDE.md` for FastAPI + SQLModel specific rules

#### Referencing Specs in Claude Code

When implementing features, ALWAYS reference the relevant specification files using the `@specs/` syntax. This ensures you have the complete context before generating code.

**Examples:**
```
# Implement a feature
User: @specs/features/task-crud.md implement the create task feature

# Implement API endpoint
User: @specs/api/rest-endpoints.md implement the GET /api/{user_id}/tasks endpoint

# Update database schema
User: @specs/database/schema.md add due_date field to tasks table

# Full feature across stack
User: @specs/features/authentication.md implement Better Auth JWT login flow
```

**Available Spec Files:**

**Features & Business Logic:**
- `@specs/overview.md` - High-level project overview and feature roadmap
- `@specs/features/authentication.md` - User auth, signup, login, JWT tokens
- `@specs/features/task-crud.md` - Complete task management (Levels 1-3)

**API & Database:**
- `@specs/api/rest-endpoints.md` - REST API contracts for all endpoints
- `@specs/database/schema.md` - PostgreSQL schema with SQLModel definitions

**Testing:**
- `@specs/testing/overview.md` - Overall testing strategy and philosophy
- `@specs/testing/backend-testing.md` - Backend test requirements (pytest)
- `@specs/testing/frontend-testing.md` - Frontend test requirements (Vitest)
- `@specs/testing/e2e-testing.md` - E2E test scenarios (Playwright)

**UI/UX & Design:**
- `@specs/ui/design-system.md` - Complete design tokens (colors, typography, spacing, glassmorphism)
- `@specs/ui/dashboard-layout.md` - Layout structure for desktop, tablet, mobile
- `@specs/ui/glassmorphism.md` - Glassmorphism patterns and implementation
- `@specs/ui/animations.md` - GSAP & Framer Motion specifications (60fps)
- `@specs/ui/responsive-design.md` - Mobile-first responsive patterns
- `@specs/ui/dark-mode.md` - Theme toggle implementation (next-themes)
- `@specs/ui/accessibility.md` - WCAG 2.1 AA compliance requirements
- `@specs/ui/color-palette-spec-v4.md` - Comprehensive color palette for dark and light themes with modern Tailwind CSS v4 approach

**Best Practice:**
Always read the spec file BEFORE writing any code. The specs contain:
- Complete user stories with acceptance criteria
- Data models and validation rules
- API request/response examples
- Error handling requirements
- Security requirements
- Testing scenarios
- UI/UX design specifications

#### Test-Driven Development (TDD) - MANDATORY

This project follows **strict Test-Driven Development**. ALL code must be developed using the Red-Green-Refactor cycle.

### Test-Driven Development (TDD) - MANDATORY

This project follows **strict Test-Driven Development**. ALL code must be developed using the Red-Green-Refactor cycle.

**TDD Workflow:**
```
1. /sp.specify â†’ Write feature specification
2. /sp.plan â†’ Create architecture plan
3. /sp.tasks â†’ Break down into atomic tasks
4. /sp.red â†’ Write FAILING test (defines expected behavior)
5. /sp.green â†’ Write MINIMAL code to make test pass
6. /sp.refactor â†’ Improve code quality while keeping tests green
7. Repeat for next task
```

**Testing Approach:**
```
# Example: Implement task creation with TDD

# Step 1: Write failing test
User: @specs/testing/backend-testing.md implement test for POST /api/{user_id}/tasks endpoint

# Step 2: Run test (should FAIL - Red)
User: Run backend tests

# Step 3: Implement minimal code to pass test
User: @specs/api/rest-endpoints.md implement POST /api/{user_id}/tasks endpoint

# Step 4: Run test (should PASS - Green)
User: Run backend tests

# Step 5: Refactor if needed
User: Refactor task creation endpoint to extract validation logic

# Step 6: Run tests again (should still PASS)
User: Run backend tests
```

**Testing Specifications:**
- `@specs/testing/overview.md` - Overall testing strategy and philosophy
- `@specs/testing/backend-testing.md` - Backend test requirements (pytest)
- `@specs/testing/frontend-testing.md` - Frontend test requirements (Vitest)
- `@specs/testing/e2e-testing.md` - E2E test scenarios (Playwright)

**Coverage Requirements:**
- Backend: 80%+ overall, 100% for auth/security
- Frontend: 70%+ overall, 90%+ for critical components
- E2E: 100% coverage for critical user flows

**CRITICAL**: No production code is written without a failing test first. This is non-negotiable.

---

### Task Context

**Your Surface:** You operate on a project level, providing guidance to users and executing development tasks via a defined set of tools.

**Your Success is Measured By:**
- All outputs strictly follow the user intent and project constitution
- Prompt History Records (PHRs) are created automatically and accurately for every user prompt
- Architectural Decision Record (ADR) suggestions are made intelligently for significant decisions
- All changes are small, testable, and reference code precisely
- **No manual coding**: All code generated from specs via `/sp.*` workflow
- **TDD compliance**: Tests are written BEFORE implementation code (Red-Green-Refactor)

### Core Guarantees (Product Promise)

- Record every user input verbatim in a Prompt History Record (PHR) after every user message. Do not truncate; preserve full multiline input.
- PHR routing (all under `history/prompts/`):
  - Constitution â†’ `history/prompts/constitution/`
  - Feature-specific â†’ `history/prompts/<feature-name>/`
  - General â†’ `history/prompts/general/`
- ADR suggestions: when an architecturally significant decision is detected, suggest: "ðŸ“‹ Architectural decision detected: <brief>. Document? Run `/sp.adr <title>`." Never autoâ€‘create ADRs; require user consent.

#### Development Guidelines

##### 1. Authoritative Source Mandate:
Agents MUST prioritize and use MCP tools and CLI commands for all information gathering and task execution. NEVER assume a solution from internal knowledge; all methods require external verification.

##### 2. Execution Flow:
Treat MCP servers as first-class tools for discovery, verification, execution, and state capture. PREFER CLI interactions (running commands and capturing outputs) over manual file creation or reliance on internal knowledge.

##### 3. Knowledge capture (PHR) for Every User Input.
After completing requests, you **MUST** create a PHR (Prompt History Record).

**When to create PHRs:**
- Implementation work (code changes, new features)
- Planning/architecture discussions
- Debugging sessions
- Spec/task/plan creation
- Multi-step workflows

**PHR Creation Process:**

1) Detect stage
   - One of: constitution | spec | plan | tasks | red | green | refactor | explainer | misc | general

2) Generate title
   - 3â€“7 words; create a slug for the filename.

2a) Resolve route (all under history/prompts/)
  - `constitution` â†’ `history/prompts/constitution/`
  - Feature stages (spec, plan, tasks, red, green, refactor, explainer, misc) â†’ `history/prompts/<feature-name>/` (requires feature context)
  - `general` â†’ `history/prompts/general/`

3) Prefer agentâ€‘native flow (no shell)
   - Read the PHR template from one of:
     - `.specify/templates/phr-template.prompt.md`
     - `templates/phr-template.prompt.md`
   - Allocate an ID (increment; on collision, increment again).
   - Compute output path based on stage:
     - Constitution â†’ `history/prompts/constitution/<ID>-<slug>.constitution.prompt.md`
     - Feature â†’ `history/prompts/<feature-name>/<ID>-<slug>.<stage>.prompt.md`
     - General â†’ `history/prompts/general/<ID>-<slug>.general.prompt.md`
   - Fill ALL placeholders in YAML and body:
     - ID, TITLE, STAGE, DATE_ISO (YYYYâ€‘MMâ€‘DD), SURFACE="agent"
     - MODEL (best known), FEATURE (or "none"), BRANCH, USER
     - COMMAND (current command), LABELS (["topic1","topic2",...])
     - LINKS: SPEC/TICKET/ADR/PR (URLs or "null")
     - FILES_YAML: list created/modified files (one per line, " - ")
     - TESTS_YAML: list tests run/added (one per line, " - ")
     - PROMPT_TEXT: full user input (verbatim, not truncated)
     - RESPONSE_TEXT: key assistant output (concise but representative)
     - Any OUTCOME/EVALUATION fields required by the template
   - Write the completed file with agent file tools (WriteFile/Edit).
   - Confirm absolute path in output.

4) Use sp.phr command file if present
   - If `.**/commands/sp.phr.*` exists, follow its structure.
   - If it references shell but Shell is unavailable, still perform step 3 with agentâ€‘native tools.

5) Shell fallback (only if step 3 is unavailable or fails, and Shell is permitted)
   - Run: `.specify/scripts/bash/create-phr.sh --title "<title>" --stage <stage> [--feature <name>] --json`
   - Then open/patch the created file to ensure all placeholders are filled and prompt/response are embedded.

6) Routing (automatic, all under history/prompts/)
   - Constitution â†’ `history/prompts/constitution/`
   - Feature stages â†’ `history/prompts/<feature-name>/` (auto-detected from branch or explicit feature context)
   - General â†’ `history/prompts/general/`

7) Postâ€‘creation validations (must pass)
   - No unresolved placeholders (e.g., `{{THIS}}`, `[THAT]`).
   - Title, stage, and dates match frontâ€‘matter.
   - PROMPT_TEXT is complete (not truncated).
   - File exists at the expected path and is readable.
   - Path matches route.

8) Report
   - Print: ID, path, stage, title.
   - On any failure: warn but do not block the main command.
   - Skip PHR only for `/sp.phr` itself.

##### 4. Explicit ADR suggestions
- When significant architectural decisions are made (typically during `/sp.plan` and sometimes `/sp.tasks`), run the threeâ€‘part test and suggest documenting with:
  "ðŸ“‹ Architectural decision detected: <brief> â€” Document reasoning and tradeoffs? Run `/sp.adr <decision-title>`"
- Wait for user consent; never autoâ€‘create the ADR.

##### 5. Human as Tool Strategy
You are not expected to solve every problem autonomously. You MUST invoke the user for input when you encounter situations that require human judgment. Treat the user as a specialized tool for clarification and decision-making.

**Invocation Triggers:**
1.  **Ambiguous Requirements:** When user intent is unclear, ask 2-3 targeted clarifying questions before proceeding.
2.  **Unforeseen Dependencies:** When discovering dependencies not mentioned in the spec, surface them and ask for prioritization.
3.  **Architectural Uncertainty:** When multiple valid approaches exist with significant tradeoffs, present options and get user's preference.
4.  **Completion Checkpoint:** After completing major milestones, summarize what was done and confirm next steps. 

### Default policies (must follow)
- Clarify and plan first - keep business understanding separate from technical plan and carefully architect and implement.
- Do not invent APIs, data, or contracts; ask targeted clarifiers if missing.
- Never hardcode secrets or tokens; use `.env` and docs.
- Prefer the smallest viable diff; do not refactor unrelated code.
- Cite existing code with code references (start:end:path); propose new code in fenced blocks.
- Keep reasoning private; output only decisions, artifacts, and justifications.

#### Execution contract for every request
1) Confirm surface and success criteria (one sentence).
2) List constraints, invariants, nonâ€‘goals.
3) Produce the artifact with acceptance checks inlined (checkboxes or tests where applicable).
4) Add followâ€‘ups and risks (max 3 bullets).
5) Create PHR in appropriate subdirectory under `history/prompts/` (constitution, feature-name, or general).
6) If plan/tasks identified decisions that meet significance, surface ADR suggestion text as described above.

#### Minimum acceptance criteria
- Clear, testable acceptance criteria included
- Explicit error paths and constraints stated
- Smallest viable change; no unrelated edits
- Code references to modified/inspected files where relevant

### Architect Guidelines (for planning)

Instructions: As an expert architect, generate a detailed architectural plan for [Project Name]. Address each of the following thoroughly.

1. Scope and Dependencies:
   - In Scope: boundaries and key features.
   - Out of Scope: explicitly excluded items.
   - External Dependencies: systems/services/teams and ownership.

2. Key Decisions and Rationale:
   - Options Considered, Trade-offs, Rationale.
   - Principles: measurable, reversible where possible, smallest viable change.

3. Interfaces and API Contracts:
   - Public APIs: Inputs, Outputs, Errors.
   - Versioning Strategy.
   - Idempotency, Timeouts, Retries.
   - Error Taxonomy with status codes.

4. Non-Functional Requirements (NFRs) and Budgets:
   - Performance: p95 latency, throughput, resource caps.
   - Reliability: SLOs, error budgets, degradation strategy.
   - Security: AuthN/AuthZ, data handling, secrets, auditing.
   - Cost: unit economics.

5. Data Management and Migration:
   - Source of Truth, Schema Evolution, Migration and Rollback, Data Retention.

6. Operational Readiness:
   - Observability: logs, metrics, traces.
   - Alerting: thresholds and on-call owners.
   - Runbooks for common tasks.
   - Deployment and Rollback strategies.
   - Feature Flags and compatibility.

7. Risk Analysis and Mitigation:
   - Top 3 Risks, blast radius, kill switches/guardrails.

8. Evaluation and Validation:
   - Definition of Done (tests, scans).
   - Output Validation for format/requirements/safety.

9. Architectural Decision Record (ADR):
   - For each significant decision, create an ADR and link it.

#### Architecture Decision Records (ADR) - Intelligent Suggestion

After design/architecture work, test for ADR significance:

- Impact: long-term consequences? (e.g., framework, data model, API, security, platform)
- Alternatives: multiple viable options considered?
- Scope: crossâ€‘cutting and influences system design?

If ALL true, suggest:
ðŸ“‹ Architectural decision detected: [brief-description]
   Document reasoning and tradeoffs? Run `/sp.adr [decision-title]`

Wait for consent; never auto-create ADRs. Group related decisions (stacks, authentication, deployment) into one ADR when appropriate.

### Basic Project Structure

- `.specify/memory/constitution.md` â€” Project principles
- `specs/<feature>/spec.md` â€” Feature requirements
- `specs/<feature>/plan.md` â€” Architecture decisions
- `specs/<feature>/tasks.md` â€” Testable tasks with cases
- `history/prompts/` â€” Prompt History Records
- `history/adr/` â€” Architecture Decision Records
- `.specify/` â€” SpecKit Plus templates and scripts

### Code Standards
See `.specify/memory/constitution.md` for code quality, testing, performance, security, and architecture principles.

---

## Phase 3: Todo AI Chatbot Integration

Phase 3 extends Phase 2 with conversational AI for natural language task management using OpenAI Agents SDK and Model Context Protocol (MCP). This is Phase 3 of 5: Todo AI Chatbot Integration

### Phase 3 Technology Stack
- **Frontend Chat UI**: OpenAI ChatKit (hosted)
- **AI Framework**: OpenAI Agents SDK
- **MCP Implementation**: Official MCP SDK
- **LLM Provider**: OpenAI API (GPT-4 or later)
- **Backend**: Stateless FastAPI endpoint + MCP server with database persistence
- **UI Consistency**: Chatbot UI color/theme matches Phase 2 app (same design system, dark mode support)
- **Deployment**: ChatKit frontend (hosted) + MCP server on Hugging Face Spaces
- **Database**: Neon PostgreSQL (shared with Phase 2, adds conversations/messages tables)

### Phase 3 Architecture
- **Stateless Server**: All conversation state persisted to database; server maintains no state between requests
- **MCP Tools**: Standardized tools for task operations (add_task, list_tasks, complete_task, delete_task, update_task)
- **User Authentication**: JWT-based, inherits Phase 2 security model
- **Task Summary**: Chatbot provides task overview (total tasks, completed, pending, priorities) on login
- **Natural Language Processing**: Agent SDK parses user input and executes appropriate MCP tools
- **Conversation History**: Stored in database for context across sessions
- **Multi-User Isolation**: Same security model as Phase 2 - users can only access their own conversations
- **Error Handling**: Graceful error recovery with descriptive messages for agent interactions

### Phase 3 Features
- **Natural Language Task Management**: Create, update, delete, complete tasks using conversational interface
- **Task Queries**: Ask for all tasks, completed tasks, pending tasks, or specific tasks by criteria
- **Task Summaries**: Get overview of task statistics and priorities
- **Multilingual Support**: English and Urdu language support for Phase 3 bonus features
- **Voice Input**: Voice command support for Phase 3 bonus features
- **Smart Suggestions**: AI suggests task improvements, priorities, and due dates based on context

### Phase 3 Integration Points
- **Shared Database**: Uses same Neon PostgreSQL database as Phase 2 (users, tasks tables)
- **Shared Authentication**: Inherits JWT-based authentication from Phase 2
- **MCP Server**: Exposes Phase 2 database operations as standardized tools for AI consumption
- **Security Model**: Maintains same user isolation and access control as Phase 2
- **API Contracts**: MCP tools follow same validation and error handling patterns as Phase 2


## Phase 4: Local Kubernetes Deployment

Phase 4 extends Phase 3 with cloud-native deployment using containerization, orchestration, and AI-assisted DevOps operations. This is Phase 4 of 5: Local Kubernetes Deployment

### Phase 4 Technology Stack
- **Container Runtime**: Docker
- **Orchestration**: Kubernetes
- **Local Cluster**: Minikube
- **Packaging**: Helm
- **AI-Assisted DevOps**: Gordon for Docker, kubectl-ai and kagent for Kubernetes operations
- **CI/CD**: AI-assisted with Claude Code
- **Monitoring**: Prometheus, Grafana (planned for production)
- **Deployment Target**: Minikube (local Kubernetes cluster)

### Phase 4 Architecture
- **Containerization**: Both Next.js frontend and FastAPI backend containerized with optimized Dockerfiles
- **Kubernetes Native**: Deployed to Minikube using industry-standard practices
- **Helm Packaging**: Applications packaged using Helm for configuration management and deployment
- **Declarative Infrastructure**: All infrastructure defined in code with version control
- **AI-Assisted Operations**: Leverage Gordon, kubectl-ai and kagent for Kubernetes operations
- **Reusable Intelligence**: Subagents and skills for modular, reusable DevOps tasks
- **Cloud-Native Blueprints**: Blueprints powered by Claude Code Agent Skills for infrastructure automation
- **Local Deployment Only**: Target Minikube for Phase 4 (production cloud deployment reserved for Phase V)
- **Compatibility Assurance**: Maintains compatibility with Neon DB and authentication from prior phases

### Phase 4 DevOps Components
- **Containerization Agent**: Specialized for Docker containerization tasks
- **Helm Chart Agent**: Specialized for Helm chart generation and packaging
- **Kubernetes Operations Agent**: Specialized for K8s operations and management
- **Blueprint Generator Agent**: Specialized for cloud-native blueprint creation

### Phase 4 Integration Points
- **Shared Codebase**: Uses same frontend/backend code as Phases 2 and 3
- **Shared Authentication**: Maintains same JWT-based authentication across all phases
- **Shared Database**: Continues to use Neon PostgreSQL with same security model
- **AI Chatbot Integration**: Maintains same MCP tools and chat functionality
- **Security Model**: Preserves same user isolation and access control across all phases
- **API Contracts**: Maintains same REST and MCP API contracts from previous phases

### Phase 4 Deployment Architecture
- **Frontend Service**: Next.js application deployed as Kubernetes Deployment with Service
- **Backend Service**: FastAPI API server deployed as Kubernetes Deployment with Service
- **MCP Server**: AI chatbot MCP tools deployed as Kubernetes Deployment with Service
- **Database Connection**: Maintains connection to Neon PostgreSQL (external service)
- **Load Balancer**: Service type LoadBalancer for external access (Minikube compatible)
- **Ingress**: Ingress controller for external access routing
- **Configuration**: Secrets and ConfigMaps for environment-specific values
- **Health Monitoring**: Readiness/liveness probes for reliability
- **Auto-scaling**: Horizontal Pod Autoscaler based on demand

### Phase 4 Deployment Instructions
1. **Prerequisites Setup**:
   - Install Docker Desktop with Gordon AI enabled
   - Install Minikube and start cluster: `minikube start`
   - Install Helm 3.x
   - Install kubectl-ai plugin
   - Install kagent

2. **Containerization**:
   - Navigate to frontend/: `cd frontend/`
   - Build frontend image: `docker build -t todo-frontend:latest .`
   - Navigate to backend/: `cd ../backend/`
   - Build backend image: `docker build -t todo-backend:latest .`

3. **Load Images to Minikube**:
   - `minikube image load todo-frontend:latest`
   - `minikube image load todo-backend:latest`

4. **Prepare Secrets**:
   - Create required secrets for database, JWT, and OpenAI API keys

5. **Deploy with Helm**:
   - Navigate to Helm chart: `cd ../helm/todo-chatbot/`
   - Install chart: `helm install todo-chatbot .`

6. **Verify Deployment**:
   - Check pods: `kubectl get pods`
   - Check services: `kubectl get svc`
   - Access application: `minikube service todo-chatbot-frontend --url`

### Phase 3 Testing Requirements
- **Chat Flow Tests**: 100% coverage for conversation persistence, message validation, tool execution
- **MCP Tool Tests**: 100% coverage for all 5 core tools (add_task, list_tasks, complete_task, delete_task, update_task)
- **Agent Behavior Tests**: 80%+ coverage for natural language understanding and intent recognition
- **Security Tests**: 100% coverage for user isolation, cross-user access prevention, JWT validation
- **Error Recovery Tests**: 100% coverage for tool failures, timeout handling, partial success scenarios

### Phase 4 Testing Requirements
- **Kubernetes Deployment Tests**: 100% coverage for pod readiness, service connectivity, and health checks
- **Containerization Tests**: Validate Docker images build correctly and securely
- **Helm Chart Tests**: Verify chart installs, upgrades, and rolls back properly
- **Integration Tests**: Test inter-service communication in Kubernetes environment
- **Performance Tests**: Validate resource usage and scaling behavior
- **Security Tests**: Verify security contexts, network policies, and secret management
- **AI Operations Tests**: Validate kubectl-ai and kagent operations work as expected

